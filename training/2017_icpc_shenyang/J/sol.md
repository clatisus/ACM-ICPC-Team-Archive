## J. New Self-describing Sequence

**题目大意**：有一个数列 $\{a_{n}\}$，$a_{1}=1$，$a_{n}=a_{n-1}+bitsum_{10}(a_{n-1})(n\ge2)$，其中 $bitsum_{10}(x)$ 表示 $x$ 在十进制下各位数字之和，求 $a_{n}$ 和 $\sum_{i=1}^{n}a_{i}$。$(n\le 10^{17})$

**题解**：注意到题目数据范围下 $bitsum$ 很小，可以大致估计一个上界 $200$（事实上达不到）。那么可以发现一个性质：每次 $a_{n}$ 相比 $a_{n-1}$ 如果在千位以上产生进位，那么 $a_{n}$ 的最后 $3$ 位一定小于 $200$，且从进位之后的位到千位必然全部是 $0$。我们预处理 $dp[i][j][k]$，记录数列某一项的第 $i$ 位（从 $0$ 开始）之前的各位数字之和为 $j$，最后 $3$ 位为 $k$，中间的各位都为 $0$，不断增加到第 $i$ 位产生进位时下列 $3$ 个数据：经过了多少项，进位后最后 $3$ 位是什么，这些项的和是多少。其中 $dp[3][j][k]$ 的初值可以暴力计算，$dp[i]$ 可以简单地用 $dp[i-1]$ 更新，只需要让 $i-1$ 位进位 $10$ 次即可~~（不知道怎么写式子）~~。这部分预处理的复杂度为 $\mathcal{O}(10^{3}\log^{3}n)$。

之后要做的事就比较简单了，我们用倍增的思想，从第 $18$ 位到第 $3$ 位依次尝试进位，剩最后 $3$ 位时暴力即可。

总复杂度 $\mathcal{O}(10^{3}\log^{3}n+T\cdot10\log n)$。